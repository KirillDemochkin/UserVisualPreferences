{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback, ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as tfb\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_binary_crossentropy(target, output):\n",
    "    \"\"\"\n",
    "    Weighted binary crossentropy between an output tensor\n",
    "    and a target tensor. POS_WEIGHT is used as a multiplier\n",
    "    for the positive targets.\n",
    "\n",
    "    Combination of the following functions:\n",
    "    * keras.losses.binary_crossentropy\n",
    "    * keras.backend.tensorflow_backend.binary_crossentropy\n",
    "    * tf.nn.weighted_cross_entropy_with_logits\n",
    "    \"\"\"\n",
    "    # transform back to logits\n",
    "    _epsilon = tfb._to_tensor(tfb.epsilon(), output.dtype.base_dtype)\n",
    "    output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n",
    "    output = tf.log(output / (1 - output))\n",
    "    # compute weighted loss\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(targets=target,\n",
    "                                                    logits=output,\n",
    "                                                    pos_weight=POS_WEIGHT)\n",
    "    return tf.reduce_mean(loss, axis=-1)\n",
    "\n",
    "\n",
    "class FPRMetrics(Callback):\n",
    "    def __init__(self, v_x, v_y):\n",
    "        self.validation_x = v_x\n",
    "        self.validation_y = v_y\n",
    "        self.best_metrics = {\"f1\": 0, \"p\": 0, \"r\": 0, \"auc\": 0}\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_x))).round()\n",
    "        val_targ = self.validation_y\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='micro')\n",
    "        _val_recall = recall_score(val_targ, val_predict, average='micro')\n",
    "        _val_precision = precision_score(val_targ, val_predict, average='micro')\n",
    "        _val_roc_auc = roc_auc_score(val_targ, val_predict, average='micro')\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        if _val_f1 > self.best_metrics['f1']:\n",
    "            self.best_metrics = {\"f1\": _val_f1, \"p\": _val_precision, \"r\": _val_recall, \"auc\": _val_roc_auc}\n",
    "        print(\"\\n current - val_f1: %f - val_precision: %f - val_recall %f, roc auc - %f\" % (_val_f1, _val_precision, _val_recall, _val_roc_auc))\n",
    "        print(\"\\n best - val_f1: %f - val_precision: %f - val_recall %f, roc auc - %f\" % (self.best_metrics['f1'], self.best_metrics['p'], self.best_metrics['r'], self.best_metrics['auc']))\n",
    "        return\n",
    "\n",
    "\n",
    "class RecallPrecisionAtK(Callback):\n",
    "    def __init__(self, v_x, v_y, k):\n",
    "        self.validation_x = v_x\n",
    "        self.validation_y = v_y\n",
    "        self.k = k\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_precision_at_k = []\n",
    "        self.val_recall_at_k = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = np.asarray(self.model.predict(self.validation_x))\n",
    "        val_targ = self.validation_y\n",
    "\n",
    "        predictions_at_k = np.argpartition(-val_predict, self.k, axis=-1)[:self.k]\n",
    "\n",
    "        recommended_at_k = np.round(val_predict[predictions_at_k])\n",
    "        relevant_at_k = np.round(val_targ[predictions_at_k])\n",
    "\n",
    "        recommended_and_relevant = np.sum(recommended_at_k * relevant_at_k)\n",
    "\n",
    "        total_relevant = np.sum(np.round(val_targ))\n",
    "\n",
    "        recall_at_k = recommended_and_relevant / total_relevant\n",
    "        precision_at_k = recommended_and_relevant / np.sum(recommended_at_k)\n",
    "\n",
    "        self.val_precision_at_k.append(precision_at_k)\n",
    "        self.val_recall_at_k.append(recall_at_k)\n",
    "        print(\"\\n - recall%d: %f - precision%d: %f\\n\" % (self.k, recall_at_k, self.k, precision_at_k))\n",
    "\n",
    "\n",
    "class Baseline(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Baseline, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Baseline, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        y = K.mean(x, axis=1)\n",
    "        return y\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[2])\n",
    "\n",
    "\n",
    "class ContextGating(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ContextGating, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                 shape=(input_shape[1], input_shape[1]),\n",
    "                                 initializer='glorot_normal',\n",
    "                                 regularizer=l2(),\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(name='b',\n",
    "                                 shape=(input_shape[1],),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        super(ContextGating, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        y = K.dot(x, self.W)  # (b, n) x (n, n) = (b, n)\n",
    "        y = y + self.b  # (b, n) + (n,)\n",
    "        y = K.tanh(y)  # (b, n)\n",
    "        y = y * x  # (b, n) * (b, n)\n",
    "        return y\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1])\n",
    "\n",
    "class SqueezeAttentionShort(Layer):\n",
    "    def __init__(self, squeeze_dimension, **kwargs):\n",
    "        super(SqueezeAttentionShort, self).__init__(**kwargs)\n",
    "        self.squeeze_dimension = squeeze_dimension\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.q0 = self.add_weight(name='q0',\n",
    "                                  shape=(self.squeeze_dimension, 1),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True,\n",
    "                                  regularizer=l2())\n",
    "        self.sb = self.add_weight(name='squeeze_block',\n",
    "                                  shape=(input_shape[2], self.squeeze_dimension),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True,\n",
    "                                  regularizer=l2())\n",
    "        super(SqueezeAttentionShort, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "    # (b, k, n) x (n, 1) \n",
    "        sq = K.dot(x, self.sb)\n",
    "        r0 = K.dot(sq, self.q0)  # (b, k, 1)\n",
    "        r0 = K.squeeze(r0, -1)\n",
    "        r0 = K.softmax(r0)  # (b, k, 1)\n",
    "        r0 = K.batch_dot(r0, x, axes=(1, 1))  # (b, k) x (b, k, n) = (b, n)\n",
    "\n",
    "        return r0  # (b, n)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[2])\n",
    "\n",
    "class SqueezeAttentionShortSqueeze(Layer):\n",
    "    def __init__(self, squeeze_dimension, **kwargs):\n",
    "        super(SqueezeAttentionShortSqueeze, self).__init__(**kwargs)\n",
    "        self.squeeze_dimension = squeeze_dimension\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.q0 = self.add_weight(name='q0',\n",
    "                                  shape=(self.squeeze_dimension, 1),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True,\n",
    "                                  regularizer=l2())\n",
    "        self.sb = self.add_weight(name='squeeze_block',\n",
    "                                  shape=(input_shape[2], self.squeeze_dimension),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True,\n",
    "                                  regularizer=l2())\n",
    "        super(SqueezeAttentionShortSqueeze, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "    # (b, k, n) x (n, 1) \n",
    "        sq = K.dot(x, self.sb)\n",
    "        r0 = K.dot(sq, self.q0)  # (b, k, 1)\n",
    "        r0 = K.squeeze(r0, -1)\n",
    "        r0 = K.softmax(r0)  # (b, k, 1)\n",
    "        r0 = K.batch_dot(r0, x, axes=(1, 1))  # (b, k) x (b, k, n) = (b, n)\n",
    "\n",
    "        return K.dot(r0, self.sb)  # (b, n)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.squeeze_dimension)\n",
    "\n",
    "\n",
    "class SqueezeExpandAttention(Layer):\n",
    "    def __init__(self, squeeze_dimension, **kwargs):\n",
    "        super(SqueezeExpandAttention, self).__init__(**kwargs)\n",
    "        self.squeeze_dimension = squeeze_dimension\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.q0 = self.add_weight(name='q0',\n",
    "                                  shape=(self.squeeze_dimension, 1),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True,\n",
    "                                  regularizer=l2())\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                 shape=(self.squeeze_dimension, self.squeeze_dimension),\n",
    "                                 initializer='glorot_normal',\n",
    "                                 trainable=True,\n",
    "                                 regularizer=l2())\n",
    "        self.b = self.add_weight(name='b',\n",
    "                                 shape=(self.squeeze_dimension,),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        self.sb = self.add_weight(name='squeeze_block',\n",
    "                                  shape=(input_shape[2], self.squeeze_dimension),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True,\n",
    "                                  regularizer=l2())\n",
    "        self.eb = self.add_weight(name='expand_block',\n",
    "                                  shape=(self.squeeze_dimension, input_shape[2]),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True,\n",
    "                                  regularizer=l2())\n",
    "        super(SqueezeExpandAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "    # (b, k, n) x (n, 1)\n",
    "        sq = K.dot(x, self.sb)\n",
    "        r0 = K.dot(sq, self.q0)  # (b, k, 1)\n",
    "        r0 = K.squeeze(r0, -1)\n",
    "        r0 = K.softmax(r0)  # (b, k, 1)\n",
    "        r0 = K.batch_dot(r0, x, axes=(1, 1))  # (b, k) x (b, k, n) = (b, n)\n",
    "        r0 = K.dot(r0, self.sb) # (b, s)\n",
    "\n",
    "        q1 = K.dot(r0, self.W)  # (b, s) x (s, s) = (b, s)\n",
    "        q1 = q1 + self.b  # (b,s)+(n,)=(b, s)\n",
    "        q1 = K.tanh(q1)  # (b, s)\n",
    "        q1 = K.dot(q1, self.eb) #  (b, n)\n",
    "\n",
    "        r1 = K.batch_dot(q1, x, axes=(1, 2))  # (b, n) x (b, k, n) = (b, k)\n",
    "        r1 = K.softmax(r1)  # (b, k)\n",
    "        r1 = K.batch_dot(r1, x, axes=(1, 1))  # (b, k) x (b, k, n) = (b, n)\n",
    "\n",
    "        return r1  # (b, n)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[2])\n",
    "\n",
    "\n",
    "class SqueezeExpandSqueezeAttention(Layer):\n",
    "    def __init__(self, squeeze_dimension, **kwargs):\n",
    "        super(SqueezeExpandSqueezeAttention, self).__init__(**kwargs)\n",
    "        self.squeeze_dimension = squeeze_dimension\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.q0 = self.add_weight(name='q0',\n",
    "                                  shape=(self.squeeze_dimension, 1),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True,\n",
    "                                  regularizer=l2())\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                 shape=(self.squeeze_dimension, self.squeeze_dimension),\n",
    "                                 initializer='glorot_normal',\n",
    "                                 trainable=True,\n",
    "                                 regularizer=l2())\n",
    "        self.b = self.add_weight(name='b',\n",
    "                                 shape=(self.squeeze_dimension,),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        self.sb = self.add_weight(name='squeeze_block',\n",
    "                                  shape=(input_shape[2], self.squeeze_dimension),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True,\n",
    "                                  regularizer=l2())\n",
    "        self.eb = self.add_weight(name='expand_block',\n",
    "                                  shape=(self.squeeze_dimension, input_shape[2]),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True,\n",
    "                                  regularizer=l2())\n",
    "        super(SqueezeExpandSqueezeAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "    # (b, k, n) x (n, 1)\n",
    "        sq = K.dot(x, self.sb)\n",
    "        r0 = K.dot(sq, self.q0)  # (b, k, 1)\n",
    "        r0 = K.squeeze(r0, -1)\n",
    "        r0 = K.softmax(r0)  # (b, k, 1)\n",
    "        r0 = K.batch_dot(r0, x, axes=(1, 1))  # (b, k) x (b, k, n) = (b, n)\n",
    "        r0 = K.dot(r0, self.sb) # (b, s)\n",
    "\n",
    "        q1 = K.dot(r0, self.W)  # (b, s) x (s, s) = (b, s)\n",
    "        q1 = q1 + self.b  # (b,s)+(n,)=(b, s)\n",
    "        q1 = K.tanh(q1)  # (b, s)\n",
    "        q1 = K.dot(q1, self.eb) #  (b, n)\n",
    "\n",
    "        r1 = K.batch_dot(q1, x, axes=(1, 2))  # (b, n) x (b, k, n) = (b, k)\n",
    "        r1 = K.softmax(r1)  # (b, k)\n",
    "        r1 = K.batch_dot(r1, x, axes=(1, 1))  # (b, k) x (b, k, n) = (b, n)\n",
    "\n",
    "        return K.dot(r1, self.sb)  # (b, s)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.squeeze_dimension)\n",
    "\n",
    "\n",
    "class AttentionBlock(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionBlock, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.q0 = self.add_weight(name='q0',\n",
    "                                  shape=(input_shape[2], 1),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True,\n",
    "                                  regularizer=l2())\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                 shape=(input_shape[2], input_shape[2]),\n",
    "                                 initializer='glorot_normal',\n",
    "                                 trainable=True,\n",
    "                                 regularizer=l2())\n",
    "        self.b = self.add_weight(name='b',\n",
    "                                 shape=(input_shape[2],),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "\n",
    "        super(AttentionBlock, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        # (b, k, n) x (n, 1)\n",
    "        r0 = K.dot(x, self.q0)  # (b, k, 1)\n",
    "        r0 = K.squeeze(r0, -1)\n",
    "        r0 = K.softmax(r0)  # (b, k, 1)\n",
    "        r0 = K.batch_dot(r0, x, axes=(1, 1))  # (b, k) x (b, k, n) = (b, n)\n",
    "\n",
    "        q1 = K.dot(r0, self.W)  # (b, n) x (n, n) = (b, n)\n",
    "        q1 = q1 + self.b  # (b,n)+(n,)=(b, n)\n",
    "        q1 = K.tanh(q1)  # (b, n)\n",
    "\n",
    "        r1 = K.batch_dot(q1, x, axes=(1, 2))  # (b, n) x (b, k, n) = (b, k)\n",
    "        r1 = K.softmax(r1)  # (b, k)\n",
    "        r1 = K.batch_dot(r1, x, axes=(1, 1))  # (b, k) x (b, k, n) = (b, n)\n",
    "\n",
    "        return r1  # (b, n)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[2])\n",
    "\n",
    "class AttentionBlockShort(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionBlockShort, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.q0 = self.add_weight(name='q0',\n",
    "                                  shape=(input_shape[2], 1),\n",
    "                                  initializer='glorot_normal',\n",
    "                                  trainable=True,\n",
    "                                  regularizer=l2())\n",
    "\n",
    "        super(AttentionBlockShort, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        # (b, k, n) x (n, 1)\n",
    "        r0 = K.dot(x, self.q0)  # (b, k, 1)\n",
    "        r0 = K.squeeze(r0, -1)\n",
    "        r0 = K.softmax(r0)  # (b, k, 1)\n",
    "        r0 = K.batch_dot(r0, x, axes=(1, 1))  # (b, k) x (b, k, n) = (b, n)\n",
    "\n",
    "        return r0  # (b, n)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs():\n",
    "    train_test_split\n",
    "    return np.load(\"ag_train_x.npy\"), np.load('test_agg_x.npy'), np.load(\"ag_train_y.npy\"), np.load('test_agg_y.npy')\n",
    "\n",
    "\n",
    "def train(model, x_train, y_train, x_test, y_test, model_save_path):\n",
    "    fpr_metrics = FPRMetrics(x_test, y_test)\n",
    "    # at_k_metrics = RecallPrecisionAtK(x_test, y_test, 10)\n",
    "    save_callback = ModelCheckpoint(\n",
    "        model_save_path,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='auto',\n",
    "        period=1)\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=4, min_lr=0.000001, min_delta=0.01)\n",
    "    \n",
    "    model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(x_test, y_test),\n",
    "        shuffle=True,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[save_callback, fpr_metrics, reduce_lr])\n",
    "\n",
    "input_length = 8\n",
    "    \n",
    "def build_model_with_AB():\n",
    "    inputs = Input(shape=(input_length, FEATURE_VECTOR_DIM))  # (batch, samples, features)\n",
    "    x = AttentionBlock()(inputs)  # (batch, features)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=FC_LAYER_SIZE, activation='relu')(x)  # (batch, units)\n",
    "    predictions = Dense(NUM_OF_CLASSES, activation='sigmoid')(x)  # (batch, classes)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model_with_AB_CG():\n",
    "    inputs = Input(shape=(input_length, FEATURE_VECTOR_DIM))  # (batch, samples, features)\n",
    "    # read feature vectors from pretrained CNN (mobilenet/squeezenet)\n",
    "    x = AttentionBlock()(inputs)  # (batch, features)\n",
    "    x = ContextGating()(x)  # (batch, features)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=FC_LAYER_SIZE, activation='relu')(x)  # (batch, units)\n",
    "    predictions = Dense(NUM_OF_CLASSES, activation='sigmoid')(x)  # (batch, classes)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "def build_model_with_ABS():\n",
    "    inputs = Input(shape=(input_length, FEATURE_VECTOR_DIM))  # (batch, samples, features)\n",
    "    # read feature vectors from pretrained CNN (mobilenet/squeezenet)\n",
    "    x = AttentionBlockShort()(inputs)  # (batch, features)\n",
    "    x = ContextGating()(x)  # (batch, features)\n",
    "    # x = Dense(units=FC_LAYER_SIZE, activation='relu')(x)  # (batch, units)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    predictions = Dense(NUM_OF_CLASSES, activation='sigmoid')(x)  # (batch, classes)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "def build_model_with_ABS_FC():\n",
    "    inputs = Input(shape=(input_length, FEATURE_VECTOR_DIM))  # (batch, samples, features)\n",
    "    # read feature vectors from pretrained CNN (mobilenet/squeezenet)\n",
    "    x = AttentionBlockShort()(inputs)  # (batch, features)\n",
    "    x = ContextGating()(x)  # (batch, features)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=FC_LAYER_SIZE, activation='relu')(x)  # (batch, units)\n",
    "    predictions = Dense(NUM_OF_CLASSES, activation='sigmoid')(x)  # (batch, classes)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "def build_model_with_SEA():\n",
    "    inputs = Input(shape=(input_length, FEATURE_VECTOR_DIM))  # (batch, samples, features)\n",
    "    # read feature vectors from pretrained CNN (mobilenet/squeezenet)\n",
    "    x = SqueezeExpandAttention(squeeze_dimension=SQUEEZE_DIMENSION)(inputs)  # (batch, features)\n",
    "    x = ContextGating()(x)  # (batch, features)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    # x = Dense(units=FC_LAYER_SIZE, activation='relu')(x)  # (batch, units)\n",
    "    predictions = Dense(NUM_OF_CLASSES, activation='sigmoid')(x)  # (batch, classes)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "def build_model_with_SEA_FC():\n",
    "    inputs = Input(shape=(input_length, FEATURE_VECTOR_DIM))  # (batch, samples, features)\n",
    "    # read feature vectors from pretrained CNN (mobilenet/squeezenet)\n",
    "    x = SqueezeExpandAttention(squeeze_dimension=SQUEEZE_DIMENSION)(inputs)  # (batch, features)\n",
    "    x = ContextGating()(x)  # (batch, features)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=FC_LAYER_SIZE, activation='relu')(x)  # (batch, units)\n",
    "    predictions = Dense(NUM_OF_CLASSES, activation='sigmoid')(x)  # (batch, classes)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model\n",
    "    \n",
    "def build_model_with_SEAS_FC():\n",
    "    inputs = Input(shape=(input_length, FEATURE_VECTOR_DIM))  # (batch, samples, features)\n",
    "    # read feature vectors from pretrained CNN (mobilenet/squeezenet)\n",
    "    x = SqueezeExpandSqueezeAttention(squeeze_dimension=SQUEEZE_DIMENSION)(inputs)  # (batch, features)\n",
    "    x = ContextGating()(x)  # (batch, features)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=FC_LAYER_SIZE, activation='relu')(x)  # (batch, units)\n",
    "    predictions = Dense(NUM_OF_CLASSES, activation='sigmoid')(x)  # (batch, classes)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "def build_model_with_SEA_FC_NOCG():\n",
    "    inputs = Input(shape=(input_length, FEATURE_VECTOR_DIM))  # (batch, samples, features)\n",
    "    # read feature vectors from pretrained CNN (mobilenet/squeezenet)\n",
    "    x = SqueezeExpandAttention(squeeze_dimension=SQUEEZE_DIMENSION)(inputs)  # (batch, features)\n",
    "    # x = ContextGating()(x)  # (batch, features)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=FC_LAYER_SIZE, activation='relu')(x)  # (batch, units)\n",
    "    predictions = Dense(NUM_OF_CLASSES, activation='sigmoid')(x)  # (batch, classes)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "def build_model_with_SAS():\n",
    "    inputs = Input(shape=(input_length, FEATURE_VECTOR_DIM))  # (batch, samples, features)\n",
    "    # read feature vectors from pretrained CNN (mobilenet/squeezenet)\n",
    "    x = SqueezeAttentionShort(squeeze_dimension=SQUEEZE_DIMENSION)(inputs)  # (batch, features)\n",
    "    x = ContextGating()(x)  # (batch, features)\n",
    "    # x = Dense(units=FC_LAYER_SIZE, activation='relu')(x)  # (batch, units)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    predictions = Dense(NUM_OF_CLASSES, activation='sigmoid')(x)  # (batch, classes)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "def build_model_with_SASS():\n",
    "    inputs = Input(shape=(input_length, FEATURE_VECTOR_DIM))  # (batch, samples, features)\n",
    "    # read feature vectors from pretrained CNN (mobilenet/squeezenet)\n",
    "    x = SqueezeAttentionShortSqueeze(squeeze_dimension=SQUEEZE_DIMENSION)(inputs)  # (batch, features)\n",
    "    x = ContextGating()(x)  # (batch, features)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    # x = Dense(units=FC_LAYER_SIZE, activation='relu')(x)  # (batch, units)\n",
    "    predictions = Dense(NUM_OF_CLASSES, activation='sigmoid')(x)  # (batch, classes)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "def build_model_with_SASS_FC():\n",
    "    inputs = Input(shape=(input_length, FEATURE_VECTOR_DIM))  # (batch, samples, features)\n",
    "    # read feature vectors from pretrained CNN (mobilenet/squeezenet)\n",
    "    x = SqueezeAttentionShort(squeeze_dimension=SQUEEZE_DIMENSION)(inputs)  # (batch, features)\n",
    "    x = ContextGating()(x)  # (batch, features)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=FC_LAYER_SIZE, activation='relu')(x)  # (batch, units)\n",
    "    predictions = Dense(NUM_OF_CLASSES, activation='sigmoid')(x)  # (batch, classes)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model\n",
    "    \n",
    "def build_model_with_SASS_FC_NOCG():\n",
    "    inputs = Input(shape=(input_length, FEATURE_VECTOR_DIM))  # (batch, samples, features)\n",
    "    # read feature vectors from pretrained CNN (mobilenet/squeezenet)\n",
    "    x = SqueezeAttentionShort(squeeze_dimension=SQUEEZE_DIMENSION)(inputs)  # (batch, features)\n",
    "    # x = ContextGating()(x)  # (batch, features)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    x = Dense(units=FC_LAYER_SIZE, activation='relu')(x)  # (batch, units)\n",
    "    predictions = Dense(NUM_OF_CLASSES, activation='sigmoid')(x)  # (batch, classes)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_baseline_model():\n",
    "    inputs = Input(shape=(input_length, FEATURE_VECTOR_DIM))\n",
    "    x = Baseline()(inputs)\n",
    "    x = Dense(units=FC_LAYER_SIZE, activation='relu')(x)  # (batch, units)\n",
    "    predictions = Dense(NUM_OF_CLASSES, activation='sigmoid')(x)  # (batch, classes)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_VECTOR_DIM = 1024\n",
    "POS_WEIGHT = 8# multiplier for positive targets, needs to be tuned\n",
    "FC_LAYER_SIZE = 256\n",
    "NUM_OF_CLASSES = 75\n",
    "SQUEEZE_DIMENSION = 256\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "x_train, x_test, y_train, y_test = get_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ SASS_FC_NOCG.pb ================\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8, 1024)           0         \n",
      "_________________________________________________________________\n",
      "squeeze_attention_short_1 (S (None, 1024)              262400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 75)                19275     \n",
      "=================================================================\n",
      "Total params: 544,075\n",
      "Trainable params: 544,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "INFO:tensorflow:Converted 6 variables to const ops.\n",
      "============ SAS.pb ================\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8, 1024)           0         \n",
      "_________________________________________________________________\n",
      "squeeze_attention_short_1 (S (None, 1024)              262400    \n",
      "_________________________________________________________________\n",
      "context_gating_1 (ContextGat (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 75)                76875     \n",
      "=================================================================\n",
      "Total params: 1,388,875\n",
      "Trainable params: 1,388,875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "INFO:tensorflow:Converted 6 variables to const ops.\n",
      "============ SEA_FC_NOCG.pb ================\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8, 1024)           0         \n",
      "_________________________________________________________________\n",
      "squeeze_expand_attention_1 ( (None, 1024)              590336    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 75)                19275     \n",
      "=================================================================\n",
      "Total params: 872,011\n",
      "Trainable params: 872,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Froze 9 variables.\n",
      "INFO:tensorflow:Converted 9 variables to const ops.\n",
      "============ Baseline.pb ================\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8, 1024)           0         \n",
      "_________________________________________________________________\n",
      "baseline_1 (Baseline)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 75)                19275     \n",
      "=================================================================\n",
      "Total params: 281,675\n",
      "Trainable params: 281,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Froze 4 variables.\n",
      "INFO:tensorflow:Converted 4 variables to const ops.\n",
      "============ ABS_FC.pb ================\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8, 1024)           0         \n",
      "_________________________________________________________________\n",
      "attention_block_short_1 (Att (None, 1024)              1024      \n",
      "_________________________________________________________________\n",
      "context_gating_1 (ContextGat (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 75)                19275     \n",
      "=================================================================\n",
      "Total params: 1,332,299\n",
      "Trainable params: 1,332,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Froze 7 variables.\n",
      "INFO:tensorflow:Converted 7 variables to const ops.\n",
      "============ SEA_FC.pb ================\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8, 1024)           0         \n",
      "_________________________________________________________________\n",
      "squeeze_expand_attention_1 ( (None, 1024)              590336    \n",
      "_________________________________________________________________\n",
      "context_gating_1 (ContextGat (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 75)                19275     \n",
      "=================================================================\n",
      "Total params: 1,921,611\n",
      "Trainable params: 1,921,611\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Froze 11 variables.\n",
      "INFO:tensorflow:Converted 11 variables to const ops.\n",
      "============ SASS_FC.pb ================\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8, 1024)           0         \n",
      "_________________________________________________________________\n",
      "squeeze_attention_short_1 (S (None, 1024)              262400    \n",
      "_________________________________________________________________\n",
      "context_gating_1 (ContextGat (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 75)                19275     \n",
      "=================================================================\n",
      "Total params: 1,593,675\n",
      "Trainable params: 1,593,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Froze 8 variables.\n",
      "INFO:tensorflow:Converted 8 variables to const ops.\n",
      "============ SEAS_FC.pb ================\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8, 1024)           0         \n",
      "_________________________________________________________________\n",
      "squeeze_expand_squeeze_atten (None, 256)               590336    \n",
      "_________________________________________________________________\n",
      "context_gating_1 (ContextGat (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 75)                19275     \n",
      "=================================================================\n",
      "Total params: 741,195\n",
      "Trainable params: 741,195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Froze 11 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 11 variables to const ops.\n",
      "============ SEA.pb ================\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8, 1024)           0         \n",
      "_________________________________________________________________\n",
      "squeeze_expand_attention_1 ( (None, 1024)              590336    \n",
      "_________________________________________________________________\n",
      "context_gating_1 (ContextGat (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 75)                76875     \n",
      "=================================================================\n",
      "Total params: 1,716,811\n",
      "Trainable params: 1,716,811\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Froze 9 variables.\n",
      "INFO:tensorflow:Converted 9 variables to const ops.\n",
      "============ SASS.pb ================\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8, 1024)           0         \n",
      "_________________________________________________________________\n",
      "squeeze_attention_short_sque (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "context_gating_1 (ContextGat (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 75)                19275     \n",
      "=================================================================\n",
      "Total params: 347,467\n",
      "Trainable params: 347,467\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "INFO:tensorflow:Converted 6 variables to const ops.\n",
      "============ AB_CG.pb ================\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8, 1024)           0         \n",
      "_________________________________________________________________\n",
      "attention_block_1 (Attention (None, 1024)              1050624   \n",
      "_________________________________________________________________\n",
      "context_gating_1 (ContextGat (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 75)                19275     \n",
      "=================================================================\n",
      "Total params: 2,381,899\n",
      "Trainable params: 2,381,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Froze 9 variables.\n",
      "INFO:tensorflow:Converted 9 variables to const ops.\n",
      "============ ABS.pb ================\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8, 1024)           0         \n",
      "_________________________________________________________________\n",
      "attention_block_short_1 (Att (None, 1024)              1024      \n",
      "_________________________________________________________________\n",
      "context_gating_1 (ContextGat (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 75)                76875     \n",
      "=================================================================\n",
      "Total params: 1,127,499\n",
      "Trainable params: 1,127,499\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "INFO:tensorflow:Froze 5 variables.\n",
      "INFO:tensorflow:Converted 5 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "models['Baseline.pb'] = build_baseline_model\n",
    "#model_save_path = 'res/AggregationModels/baseline.h5'\n",
    "\n",
    "models['AB_CG.pb'] = build_model_with_AB_CG\n",
    "#model = build_model_with_AB_CG()\n",
    "#model_save_path = 'res/res_512/AB_CG.h5'\n",
    "models['ABS.pb'] = build_model_with_ABS\n",
    "#model = build_model_with_ABS()\n",
    "#model_save_path = 'res/res_512/ABS.h5'\n",
    "models['SEA.pb'] = build_model_with_SEA\n",
    "#model = build_model_with_SEA()\n",
    "#model_save_path = 'res/res_512/SEA.h5'\n",
    "models['SAS.pb'] = build_model_with_SAS\n",
    "#model = build_model_with_SAS()\n",
    "#model_save_path = 'res/res_512/SAS.h5'\n",
    "models['SASS.pb'] = build_model_with_SASS\n",
    "#model = build_model_with_SASS()\n",
    "#model_save_path = 'res/res_512/SASS.h5'\n",
    "models['ABS_FC.pb'] = build_model_with_ABS_FC\n",
    "#model = build_model_with_ABS_FC()\n",
    "#model_save_path = 'res/res_512/ABS_FC.h5'\n",
    "models['SEA_FC.pb'] = build_model_with_SEA_FC\n",
    "#model = build_model_with_SEA_FC()\n",
    "#model_save_path = 'res/res_512/SEA_FC.h5'\n",
    "models['SEAS_FC.pb'] = build_model_with_SEAS_FC\n",
    "#model = build_model_with_SEAS_FC()\n",
    "#model_save_path = 'res/res_512/SEAS_FC.h5'\n",
    "models['SASS_FC_NOCG.pb'] = build_model_with_SASS_FC_NOCG\n",
    "#model = build_model_with_SASS_FC_NOCG()\n",
    "#model_save_path = 'res/res_512/SASS_FC_NOCG.h5'\n",
    "models['SEA_FC_NOCG.pb'] = build_model_with_SEA_FC_NOCG\n",
    "#model = build_model_with_SEA_FC_NOCG()\n",
    "#model_save_path = 'res/res_512/SEA_FC_NOCG.h5'\n",
    "models['SASS_FC.pb'] = build_model_with_SASS_FC\n",
    "#model = build_model_with_SASS_FC()\n",
    "#model_save_path = 'res/res_512/SASS_FC.h5'\n",
    "\n",
    "for save_path, model_fn in models.items():\n",
    "    K.clear_session()\n",
    "    model = model_fn()\n",
    "    #model.compile(optimizer=Adam(lr=0.0001),\n",
    "                  #loss=weighted_binary_crossentropy,\n",
    "                  #metrics=['categorical_accuracy'])\n",
    "    print('============', save_path, '================')\n",
    "    print(model.summary())\n",
    "    frozen_graph = freeze_session(K.get_session(), output_names=[out.op.name for out in model.outputs])\n",
    "    tf.train.write_graph(frozen_graph, \"res/small\", save_path, as_text=False)\n",
    "    #train(model, x_train, y_train, x_test, y_test, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
    "            session, input_graph_def, output_names, freeze_var_names)\n",
    "        \n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 21 variables.\n",
      "INFO:tensorflow:Converted 21 variables to const ops.\n",
      "2019-04-24 17:26:20.494452: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-04-24 17:26:20.607407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6325\n",
      "pciBusID: 0000:0a:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 362.50MiB\n",
      "2019-04-24 17:26:20.607448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
      "2019-04-24 17:26:20.851307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-04-24 17:26:20.851361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
      "2019-04-24 17:26:20.851367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
      "2019-04-24 17:26:20.851533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 73 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "!tflite_convert \\\n",
    "    --output_file=res/TFLITE/baeline.tflite \\\n",
    "    --graph_def_file=res/TFLITE/baseline.pb \\\n",
    "    --input_shapes=1,8,1024 \\\n",
    "    --input_arrays=input_1 \\\n",
    "    --output_arrays=dense_2/Sigmoid \\\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
