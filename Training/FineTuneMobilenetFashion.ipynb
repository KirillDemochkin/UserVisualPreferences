{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import io\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend.tensorflow_backend as tfb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "POS_WEIGHT = 7  # multiplier for positive targets, needs to be tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"/home/kdemochkin/2019_research/UserVisualPreferences/data/AmazonFashion6ImgPartitioned.npy\"\n",
    "[user_train, user_validation, user_test, Item, usernum, itemnum] = np.load(datapath, encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_items(items): \n",
    "    item_list = []\n",
    "    for i in range(itemnum):\n",
    "        item = items[i]\n",
    "        category = get_categories_from_item(item)\n",
    "        img = item[b'imgs']\n",
    "        item_list.append((img, category))\n",
    "    return item_list\n",
    "\n",
    "def build_category_dict(items, min_number_of_items_per_category):\n",
    "    categories = set()\n",
    "    for i in range(itemnum):\n",
    "        for cat_list in items[i][b'categories']:\n",
    "            for cat in cat_list:\n",
    "                if cat.decode('utf8').lower() not in stop_categories and len(cat.decode('utf8')) > 1: categories.add(cat.decode('utf8').lower())\n",
    "    categories = dict.fromkeys(list(categories), 0)\n",
    "    for i in range(itemnum):\n",
    "        for cat_list in items[i][b'categories']:\n",
    "            for cat in cat_list:\n",
    "                if cat.decode('utf8').lower() in categories: categories[cat.decode('utf8').lower()] += 1\n",
    "    sorted_cats = sorted(categories.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    top_cats = [c[0] for c in sorted_cats if c[1] >= min_number_of_items_per_category]\n",
    "    return top_cats, {top_cats[i]: i for i in range(len(top_cats))}\n",
    "\n",
    "def get_categories_from_item(item):\n",
    "    item_categories = set()\n",
    "    for cat_list in item[b'categories']:\n",
    "        for cat in cat_list:\n",
    "            if cat.decode('utf8').lower() in categories: item_categories.add(cat.decode('utf8').lower())\n",
    "    return list(item_categories)\n",
    "\n",
    "def load_image(img_bytes):\n",
    "    \n",
    "    img = preprocess_input(np.array(Image.open(io.BytesIO(img_bytes)).convert('RGB').resize((224, 224))))\n",
    "    # print(img.shape)\n",
    "    return img\n",
    "\n",
    "def cat2idx(categories):\n",
    "    cat_indices = [category_dict[c] for c in categories]\n",
    "    return np.array([1 if i in cat_indices else 0 for i in range(num_categories)])\n",
    "\n",
    "def getitem(idx):\n",
    "    img, cat = item_list[idx]\n",
    "    cat = cat2idx(cat)\n",
    "    return img, cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_categories = ['shoes & accessories: international shipping available',\n",
    "           'clothing, shoes & jewelry',\n",
    "           'boys',\n",
    "           'men',\n",
    "           'women',\n",
    "           'girls',\n",
    "           'clothing',\n",
    "           'novelty, costumes & more',\n",
    "           'jewelry: international shipping available',\n",
    "           'available for snternational shipping']\n",
    "\n",
    "categories, category_dict = build_category_dict(Item, 1000)\n",
    "num_categories = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = prepare_items(Item)\n",
    "random.shuffle(combined)\n",
    "combined = combined[:40000]\n",
    "x, y = zip(*combined)\n",
    "x = np.array([load_image(img_bytes) for img_bytes in x])\n",
    "y = np.array([cat2idx(categories) for categories in y])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, shuffle=True, random_state=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 224, 224, 3) (4000, 224, 224, 3) (36000, 75) (4000, 75)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_train', x_train)\n",
    "np.save('x_test', x_test)\n",
    "np.save('y_train', y_train)\n",
    "np.save('y_test', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = x_train\n",
    "test_x = x_test\n",
    "train_y = y_train\n",
    "test_y = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.load(\"./x_train.npy\")\n",
    "test_x = np.load(\"./x_test.npy\")\n",
    "train_y = np.load(\"./y_train.npy\")\n",
    "test_y = np.load(\"./y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkIt(seq, num):\n",
    "    avg = seq.shape[0] / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < seq.shape[0]:\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(chunkIt(train_x, int(train_x.shape[0] / 64)))\n",
    "x_test = np.array(chunkIt(test_x, int(test_x.shape[0] / 64)))\n",
    "y_train = np.array(chunkIt(train_y, int(train_y.shape[0] / 64)))\n",
    "y_test = np.array(chunkIt(test_y, int(test_y.shape[0] / 64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model\n",
      "transfer learning\n",
      "Train on 36000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "36000/36000 [==============================] - 105s 3ms/step - loss: 0.2803 - acc: 0.6876 - val_loss: 0.5850 - val_acc: 0.0670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — val_f1: 0.081735 — val_precision: 0.324151 — val_recall 0.097125\n",
      "Epoch 2/10\n",
      "36000/36000 [==============================] - 83s 2ms/step - loss: 0.2299 - acc: 0.7188 - val_loss: 0.5736 - val_acc: 0.0785\n",
      " — val_f1: 0.087956 — val_precision: 0.324485 — val_recall 0.089738\n",
      "Epoch 3/10\n",
      "36000/36000 [==============================] - 84s 2ms/step - loss: 0.2207 - acc: 0.7238 - val_loss: 0.5690 - val_acc: 0.0963\n",
      " — val_f1: 0.097788 — val_precision: 0.328518 — val_recall 0.092334\n",
      "Epoch 4/10\n",
      "36000/36000 [==============================] - 84s 2ms/step - loss: 0.2161 - acc: 0.7291 - val_loss: 0.5654 - val_acc: 0.1128\n",
      " — val_f1: 0.107433 — val_precision: 0.329870 — val_recall 0.099820\n",
      "Epoch 5/10\n",
      "36000/36000 [==============================] - 84s 2ms/step - loss: 0.2122 - acc: 0.7310 - val_loss: 0.5659 - val_acc: 0.1072\n",
      " — val_f1: 0.101647 — val_precision: 0.333760 — val_recall 0.094330\n",
      "Epoch 6/10\n",
      "36000/36000 [==============================] - 84s 2ms/step - loss: 0.2100 - acc: 0.7365 - val_loss: 0.5658 - val_acc: 0.1138\n",
      " — val_f1: 0.102818 — val_precision: 0.333218 — val_recall 0.095129\n",
      "Epoch 7/10\n",
      "36000/36000 [==============================] - 84s 2ms/step - loss: 0.2074 - acc: 0.7385 - val_loss: 0.5622 - val_acc: 0.1275\n",
      " — val_f1: 0.107897 — val_precision: 0.330526 — val_recall 0.096826\n",
      "Epoch 8/10\n",
      "36000/36000 [==============================] - 84s 2ms/step - loss: 0.2058 - acc: 0.7405 - val_loss: 0.5621 - val_acc: 0.1308\n",
      " — val_f1: 0.108466 — val_precision: 0.336551 — val_recall 0.097624\n",
      "Epoch 9/10\n",
      "36000/36000 [==============================] - 84s 2ms/step - loss: 0.2039 - acc: 0.7432 - val_loss: 0.5595 - val_acc: 0.1405\n",
      " — val_f1: 0.113572 — val_precision: 0.333871 — val_recall 0.100719\n",
      "Epoch 10/10\n",
      "36000/36000 [==============================] - 84s 2ms/step - loss: 0.2031 - acc: 0.7420 - val_loss: 0.5600 - val_acc: 0.1427\n",
      " — val_f1: 0.116282 — val_precision: 0.338882 — val_recall 0.102915\n",
      "setup finetuning\n",
      "finetune train\n",
      "Train on 36000 samples, validate on 4000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 194s 5ms/step - loss: 0.1994 - acc: 0.7491 - val_loss: 0.1735 - val_acc: 0.8237\n",
      " — val_f1: 0.649618 — val_precision: 0.577704 — val_recall 0.793372\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 172s 5ms/step - loss: 0.1951 - acc: 0.7549 - val_loss: 0.1725 - val_acc: 0.8237\n",
      " — val_f1: 0.651929 — val_precision: 0.579366 — val_recall 0.794670\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 173s 5ms/step - loss: 0.1940 - acc: 0.7555 - val_loss: 0.1719 - val_acc: 0.8243\n",
      " — val_f1: 0.652825 — val_precision: 0.579577 — val_recall 0.795867\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 172s 5ms/step - loss: 0.1934 - acc: 0.7578 - val_loss: 0.1716 - val_acc: 0.8235\n",
      " — val_f1: 0.653372 — val_precision: 0.580011 — val_recall 0.796666\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 172s 5ms/step - loss: 0.1922 - acc: 0.7587 - val_loss: 0.1714 - val_acc: 0.8247\n",
      " — val_f1: 0.653730 — val_precision: 0.580058 — val_recall 0.797065\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 172s 5ms/step - loss: 0.1928 - acc: 0.7571 - val_loss: 0.1712 - val_acc: 0.8245\n",
      " — val_f1: 0.653622 — val_precision: 0.579756 — val_recall 0.797265\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 172s 5ms/step - loss: 0.1921 - acc: 0.7587 - val_loss: 0.1710 - val_acc: 0.8245\n",
      " — val_f1: 0.653824 — val_precision: 0.580014 — val_recall 0.797664\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 173s 5ms/step - loss: 0.1916 - acc: 0.7566 - val_loss: 0.1709 - val_acc: 0.8253\n",
      " — val_f1: 0.654340 — val_precision: 0.580490 — val_recall 0.797465\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 172s 5ms/step - loss: 0.1914 - acc: 0.7584 - val_loss: 0.1708 - val_acc: 0.8257\n",
      " — val_f1: 0.654299 — val_precision: 0.580522 — val_recall 0.797664\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 173s 5ms/step - loss: 0.1910 - acc: 0.7628 - val_loss: 0.1707 - val_acc: 0.8253\n",
      " — val_f1: 0.654472 — val_precision: 0.580578 — val_recall 0.797664\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 171s 5ms/step - loss: 0.1911 - acc: 0.7579 - val_loss: 0.1706 - val_acc: 0.8250\n",
      " — val_f1: 0.654588 — val_precision: 0.581105 — val_recall 0.797365\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 172s 5ms/step - loss: 0.1911 - acc: 0.7593 - val_loss: 0.1704 - val_acc: 0.8247\n",
      " — val_f1: 0.654883 — val_precision: 0.581296 — val_recall 0.797964\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 172s 5ms/step - loss: 0.1905 - acc: 0.7570 - val_loss: 0.1704 - val_acc: 0.8255\n",
      " — val_f1: 0.655096 — val_precision: 0.581259 — val_recall 0.798363\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 171s 5ms/step - loss: 0.1905 - acc: 0.7583 - val_loss: 0.1703 - val_acc: 0.8260\n",
      " — val_f1: 0.654939 — val_precision: 0.581081 — val_recall 0.798263\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 172s 5ms/step - loss: 0.1903 - acc: 0.7569 - val_loss: 0.1703 - val_acc: 0.8260\n",
      " — val_f1: 0.655157 — val_precision: 0.581467 — val_recall 0.797864\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 173s 5ms/step - loss: 0.1905 - acc: 0.7598 - val_loss: 0.1702 - val_acc: 0.8255\n",
      " — val_f1: 0.655405 — val_precision: 0.581568 — val_recall 0.798463\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 172s 5ms/step - loss: 0.1900 - acc: 0.7606 - val_loss: 0.1701 - val_acc: 0.8263\n",
      " — val_f1: 0.655287 — val_precision: 0.581334 — val_recall 0.798762\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 172s 5ms/step - loss: 0.1900 - acc: 0.7612 - val_loss: 0.1701 - val_acc: 0.8260\n",
      " — val_f1: 0.655842 — val_precision: 0.581554 — val_recall 0.799461\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 172s 5ms/step - loss: 0.1900 - acc: 0.7585 - val_loss: 0.1700 - val_acc: 0.8255\n",
      " — val_f1: 0.655769 — val_precision: 0.581554 — val_recall 0.799561\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 172s 5ms/step - loss: 0.1897 - acc: 0.7589 - val_loss: 0.1699 - val_acc: 0.8250\n",
      " — val_f1: 0.655715 — val_precision: 0.581790 — val_recall 0.798962\n",
      "saving\n"
     ]
    }
   ],
   "source": [
    "class FPRMetrics(Callback):\n",
    "    def __init__(self, v_x, v_y):\n",
    "        self.validation_x = v_x\n",
    "        self.validation_y = v_y\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_x))).round()\n",
    "        val_targ = self.validation_y\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='weighted')\n",
    "        _val_recall = recall_score(val_targ, val_predict, average='weighted')\n",
    "        _val_precision = precision_score(val_targ, val_predict, average='weighted')\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print(\" — val_f1: %f — val_precision: %f — val_recall %f\" %(_val_f1, _val_precision, _val_recall))\n",
    "        return\n",
    "\n",
    "\n",
    "def weighted_binary_crossentropy(target, output):\n",
    "    \"\"\"\n",
    "    Weighted binary crossentropy between an output tensor\n",
    "    and a target tensor. POS_WEIGHT is used as a multiplier\n",
    "    for the positive targets.\n",
    "\n",
    "    Combination of the following functions:\n",
    "    * keras.losses.binary_crossentropy\n",
    "    * keras.backend.tensorflow_backend.binary_crossentropy\n",
    "    * tf.nn.weighted_cross_entropy_with_logits\n",
    "    \"\"\"\n",
    "    # transform back to logits\n",
    "    _epsilon = tfb._to_tensor(tfb.epsilon(), output.dtype.base_dtype)\n",
    "    output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n",
    "    output = tf.log(output / (1 - output))\n",
    "    # compute weighted loss\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(targets=target,\n",
    "                                                    logits=output,\n",
    "                                                    pos_weight=POS_WEIGHT)\n",
    "    return tf.reduce_mean(loss, axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "# set all parameters\n",
    "IM_WIDTH, IM_HEIGHT = 224, 224\n",
    "BAT_SIZE = 128\n",
    "NUM_CLASSES = num_categories\n",
    "NUM_LAYERS_TO_FREEZE = 22  # 3 conv blocks\n",
    "\n",
    "top_epochs = 10\n",
    "fit_epochs = 10\n",
    "\n",
    "top_layers_checkpoint_path = 'res/checkpoint_top_best.hdf5'\n",
    "fine_tuned_checkpoint_path = 'res/checkpoint_fine_tuned_best.hdf5'\n",
    "new_extended_mobilenet_weights = 'res/final_weights.hdf5'\n",
    "\n",
    "\n",
    "# build and transfer learn base model\n",
    "print('building model')\n",
    "base_model = MobileNet(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(IM_WIDTH, IM_HEIGHT, 3)\n",
    ")\n",
    "top_layer = base_model.output\n",
    "top_layer = GlobalAveragePooling2D()(top_layer)\n",
    "top_layer = Dropout(rate=0.5)(top_layer)\n",
    "predictions = Dense(NUM_CLASSES, activation='sigmoid')(top_layer)\n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "fpr_metrics = FPRMetrics(test_x, test_y)\n",
    "\n",
    "for layer in model.layers[:NUM_LAYERS_TO_FREEZE]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[NUM_LAYERS_TO_FREEZE:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "mc_top = ModelCheckpoint(\n",
    "    top_layers_checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    period=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7)\n",
    "\n",
    "print('transfer learning')\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=0.001, decay=0.2),\n",
    "    loss=weighted_binary_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    batch_size=BAT_SIZE,\n",
    "    epochs=top_epochs,\n",
    "    validation_data=(test_x, test_y),\n",
    "    callbacks=[fpr_metrics, mc_top, early_stopping],\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# fine tuning\n",
    "print('setup finetuning')\n",
    "mc_fit = ModelCheckpoint(\n",
    "    fine_tuned_checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    period=1\n",
    ")\n",
    "\n",
    "for layer in model.layers[:NUM_LAYERS_TO_FREEZE]:\n",
    "    layer.trainable = True\n",
    "for layer in model.layers[NUM_LAYERS_TO_FREEZE:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=0.0001, decay=0.1),\n",
    "    loss=weighted_binary_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print('finetune train')\n",
    "model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    batch_size=BAT_SIZE,\n",
    "    epochs=fit_epochs,\n",
    "    callbacks=[fpr_metrics, mc_fit, early_stopping],\n",
    "    validation_data=(test_x, test_y),\n",
    "    shuffle=True,\n",
    ")\n",
    "print('saving')\n",
    "model.save(new_extended_mobilenet_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
